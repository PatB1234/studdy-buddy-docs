{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Pages Click the following links for specific details about the development process: Backend Frontend Core Functions StudyBuddy is a unique app developed by Pratyush Bindal from St. Christopher's School of Bahrain, registered under the MIT License. The app is developed from the ground up (with the essential boilerplate(s)) and aims to revolutionise the learning experience for students in my school by incorporating AI Large-Language models into it. StudyBuddy uses user-created notes to aid the student in revising with interactive approaches such as: Automatic AI summarising Flashcards generation Question & Answers quizzes to test your knowledge of the notes The ability to ask questions to a knowledgeable source (the AI) StudyBuddy utilises the new Gemini 2.0-Flash model from google to provide a cost-effective yet intelligent and correct solution. How was it built? Rome wasn't built in a day \u2014 neither was StudyBuddy. This is an ongoing project that I started in September of 2024 when I realised that I needed questions to test my knowledge of my notes for an upcoming exam. From there, I began development of the app, which comprises of a few main parts The backend: - Built in python with FastAPI & Uvicorn - Uses sqlite3 for reliable data storage - Encrypts user passwords with bcrypt cryptography to ensure security - Uses the Gemini 2.0-Flash API for AI communication The Frontend: - Uses AngularJS alongside AngularMaterial to provide a responsive, clean and polished website with ease-of-use for the the user","title":"Home"},{"location":"#pages","text":"Click the following links for specific details about the development process: Backend Frontend Core Functions StudyBuddy is a unique app developed by Pratyush Bindal from St. Christopher's School of Bahrain, registered under the MIT License. The app is developed from the ground up (with the essential boilerplate(s)) and aims to revolutionise the learning experience for students in my school by incorporating AI Large-Language models into it. StudyBuddy uses user-created notes to aid the student in revising with interactive approaches such as: Automatic AI summarising Flashcards generation Question & Answers quizzes to test your knowledge of the notes The ability to ask questions to a knowledgeable source (the AI) StudyBuddy utilises the new Gemini 2.0-Flash model from google to provide a cost-effective yet intelligent and correct solution.","title":"Pages"},{"location":"#how-was-it-built","text":"Rome wasn't built in a day \u2014 neither was StudyBuddy. This is an ongoing project that I started in September of 2024 when I realised that I needed questions to test my knowledge of my notes for an upcoming exam. From there, I began development of the app, which comprises of a few main parts The backend: - Built in python with FastAPI & Uvicorn - Uses sqlite3 for reliable data storage - Encrypts user passwords with bcrypt cryptography to ensure security - Uses the Gemini 2.0-Flash API for AI communication The Frontend: - Uses AngularJS alongside AngularMaterial to provide a responsive, clean and polished website with ease-of-use for the the user","title":"How was it built?"},{"location":"Backend/","text":"The backend stores data in a typical SQL-based database. For python, we used sqlite3 . This is a lightweight, high-speed and efficient database built for small-medium scale applications such as mine. As I am paying for the server out of pocket, efficient use of storage allocation was a necessity. SQLite fulfilled these requirements and did not deprive me of any modern features to make my code cleaner. To run the application, we used an ASGI server (Asynchronous server gateway interface) to run the API; specifically we used uvicorn . Again, it is lightweight, efficient and can handle asynchronous method calls to allow for an overall faster user experience. Data Structures All of the data sent from the frontend is sent in the form of JSON data. To allow our backend to interpret this, we used custom BaseModels for each POST & GET call. For example, if our frontend called a login function such as: this.http.post(this.URL + \"/check_student_login\", {email: \"example@example.com\", username: \"example\", password: \"example\"}).subscribe((res: any) => { Where email , username and password are the JSON parameters. As a result our backend model would look like: from pydantic import BaseModel # Module to create the models class PostLoginCheckStudentModel(BaseModel): email: str username: str password: str And the API would receive the call like so: @app.post(\"/api/check_student_login\") async def check_student_login_post(user: PostLoginCheckStudentModel): return check_student_login(user.email, user.password) # Calls a function on the backend These Data Structures are repeated throughout the API and are paramount to our data manipulation methods. Encryption Firstly, all passwords are encrypted before being stored in the backend. They are encrypted using Passlib's CryptContext module with 'bcrypt' as the schema. The password is encrypted with the following code: from pydantic import BaseModel # Import module pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\") # Identify the schema used def hash_password(password): # Take a plaintext password & convert it to ciphertext return pwd_context.hash(password) This will encrypt our password. It is extremely secure as each password is non-reversible. This results in the same input string having a variable output hash as the starting 'salt' used by the algorithm will be different. For example, an input password of 1234 could result in: - $2b$12$zProG7RawgHpdXZ9RfxYZ.pcwZy4N29C6mRzBb8yAFvoHc5TSSyZC - $2b$12$0DPNbWZDAX5fJl4pyBHnIuWiLk.2w/rxU/MnuKFznmjouUMjFxW5. - $2b$12$U6PDFiGrqooLxsnHJ7X9gehpzH3tLiI./BH8oj3HejMSyZvGHPneC - $2b$12$YJK4L0S8pcFKokWUYqf1VuDtjxy.KptvvBN9VTJIvTPTuwc36KwAe - $2b$12$MWwHq8PHskJqF2EoGOI60..J92SVyjD5FHVc4Ugbv7ZnD10Wso6yO - $2b$12$r5qvt.4ik//TSFaVWxWZ3uFGdmUXJL35.FXeeb2uDiWSQSZYQWv0i With there being a large number of potential passwords based on the starting 'salt'. To verify the value of our password, we do not reverse the hash. This is because reversing the hash is impossible. Instead, we use an inbuilt function that compares the plain-text to the hashed cipher-text. This functionality is used when authenticating a user during login and is done as such: from pydantic import BaseModel # Import module pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\") # Identify the schema used def verify_password(unhashed, hashed): return pwd_context.verify(unhashed, hashed) # Returns a boolean This function compares the original 'salt' and 'work factor' (Number of encryption iterations) and calculates whether the hash could have been derived from this input. If the algorithm deems it possible, then a boolean value of True is returned, otherwise the function returns False . Tokens When the frontend needs to make any request to the backend, it needs to provide a token. This token is valid for 7 days and stores the name , email and id of the user (student) that is currently logged in. When a user attempts to login, the details they input are checked against the database. If the email and password inputted align with an email and password from the database, a token is created and sent to the frontend. The token is created using the code: def get_user_token(student: Student): to_encode = { 'details' : {'name': student.name, 'email': student.email, 'id': student.id}, 'expiry' : str(datetime.utcnow() + timedelta(minutes = ACCESS_TOKEN_EXPIRE_MINUTES)) } return jwt.encode(to_encode, SECRET_KEY, algorithm = ALGORITHM) Where SECRET_KEY is a 256-bit custom code that is used for encryption and the algorithm is HS256. This token is then stored in the user's browser data. As a result of this, the user will not have to log in to the website on every occurrence of accessing the website. The frontend injects this token into every request as shown by the code: @Injectable() export class CookieInterceptor implements HttpInterceptor { private platformId = inject(PLATFORM_ID); intercept(request: HttpRequest<unknown>, next: HttpHandler): Observable<HttpEvent<unknown>> { // Intercepts an incoming request let token: string | undefined; if (isPlatformBrowser(this.platformId)) { token = document.cookie.split(\"; \").find((row) => row.startsWith(\"token=\"))?.split(\"=\")[1]; } // Extracts the token from the web-browser const modifiedRequest = request.clone({ withCredentials: true, setHeaders: token ? { 'token': token } : {} // Adds the token to the request }); return next.handle(modifiedRequest); // Sends the request to the API } } Once the backend receives this token, it then verifies the token in every single function before even executing the intended request of the method call. This is done through the code: @app.post(\"/api/function_name\") async def function_name(request: Request): token_res = validate_student(request.headers.get('token')) # Runs a backend function to validate the token by extracting the user details and checking the expiry of the token if token_res == False: return JSONResponse(status_code=401, content={\"message\": \"Invalid token\"}) # Prevents any functions if the token is invalid else: # Execute the intended code here To validate the token, the code firsts calls the function validate_student() : def validate_student(token): try: res = get_student_from_token(token) if res == \"Token Expired\": # Checks if the token is past its expiry date return False else: # Returns details in the form of a list return [res['name'], res['email'], res['id']] # If the token is invalid, return False except InvalidTokenError: return False # If the token cannot be decoded, return False except InvalidSignatureError: # Checks if the user has tried to use token injection, resulting in an invalid token return False To get the res variable, our code initially decodes the token using the get_student_from_token(token: str) function: def get_student_from_token(token): payload = jwt.decode(token, SECRET_KEY, algorithms = [ALGORITHM]) expiry = payload.get('expiry') if datetime.utcnow() >= datetime.strptime(expiry, '%Y-%m-%d %H:%M:%S.%f'): # Compares the expiry date to the current date based on UCT return \"Token Expired\" else: return payload.get('details') # Returns the details as a dictionary of the name, email and UID This means that an expired or invalid token will immediately be rejected but a valid and correct token will be decoded. The app then performs all of its functions based on this data, allowing the app to extract the user's notes based on the OWNER_EMAIL property of each file, ensuring the privacy of user data and maintains the user experience. If the app returns a 401 error due to a bad token, the frontend intercepts this error and redirects the user to a login/sign-up page, as shown in the code: @Injectable() export class ErrorInterceptor implements HttpInterceptor { constructor(private router: Router, private route: ActivatedRoute) {} getChildRoute(route: ActivatedRoute): ActivatedRoute { while (route.firstChild) { route = route.firstChild; } return route; } intercept(request: HttpRequest<any>, next: HttpHandler): Observable<HttpEvent<any>> { const modifiedRequest = request.clone({ // Clones any incoming requests headers: request.headers.set('X-Requested-With', 'XMLHttpRequest'), withCredentials: true }); return next.handle(modifiedRequest).pipe( tap(() => {}, (err: any) => { if (err instanceof HttpErrorResponse) { // Checks if we have received an error if (err.status != 401 ) { return; } this.router.navigate(['/login']); // Prevents the request from going through and redirects to login page instead } })); } } This all ensures that the user can use the app easily, as they do not have to specify their ID when trying to use the app's functions whilst also preventing bad actors from accessing user data. There is one exception to each API call having a token requirements. This is the cloud_check() function and is used by me to check if the API is responding to API calls. It is a simple get API call: @app.get(\"/api/cloud_check\") async def cloud_check(): return True And was initially used by my service provider to notify me if my API goes down. This is the only potential vulnerability evident to me, and is more dependent on my provider's (Linode) protection to unauthorised IPv6 & IPv4 calls to the server. When calling the method, it should return the following page: Storing user files When a user uploads a file, it is stored in our backend as a raw .PDF file. These files are not encrypted and are stored as their raw content. Their security is dependent upon the security of our service provider, Linode. The only feasible point of interception is when the file is being transmitted to the Backend from the Frontend. Before even allowing the data to be uploaded, we first have to verify its size. Gemini AI, like other commerical AIs converts input data and prompts to tokens that it can decode and understand. Similarly, input files are converted to tokens. There is a limit to the number of tokens that the AI can handle. To ensure that the files aren't too large (i.e. too many tokens), we use the count_tokens function of the API. This counts the tokens with the code: token_no = client.models.count_tokens(model=model_name,contents=client.files.upload(file=file_path, config={'display_name': 'test_data'})).total_tokens We then compare it to the limit, returning a boolean value depending on the result. However, we also have this statement encapsulated in a try...except... loop as if this request fails, then we know that the file is too large so we automatically reject it. NOTE: Files such as handwritten files have a lower capacity as they require more tokens and often cannot be decoded by the AI. To circumvent this, I am working on implementing a form of Vision AI to convert handwritten text to PDF Format. However, this also has its limitations. Volatile Data Current Notes The note that the user currently has selected is stored as a python array, as this allows for quick read/write times and this data does not need to be permanent as the user can simply reselect the notes they are using. Caching We also have caching in place. Previously, it would take anywhere from 30s - 2min for the flashcard & question-answer functionality to respond. To avoid this, any generated flashcards are stored in an array. Before generating them, the code checks if flashcards for the given notes already exist. If they do, then those flashcards are returned. If not, flashcards are generated and stored. Similarly, the code generates 10 questions at a time and stores them in an array relative to the file. When a question is requested, a question is removed from this list and sent. Once the number of cached questions drops below 3, a new set of questions are requested from the AI. This reduces the wait-time for the user and also makes it more cost-effective on my part as I have to pay for fewer requests, albeit there is a larger size per request. Non-volatile data Notes The notes stored are non-volatile as they are stored as PDF data. Login Data User information such as their emails, password and UID's are stored in a sqlite3 database on the SSD of our server Tokens Tokens are actually stored on the browser, and sent to the backend on a per-request basis. The Backend simply verifies their validity therefore they are considered non-volatile.","title":"Backend"},{"location":"Backend/#data-structures","text":"All of the data sent from the frontend is sent in the form of JSON data. To allow our backend to interpret this, we used custom BaseModels for each POST & GET call. For example, if our frontend called a login function such as: this.http.post(this.URL + \"/check_student_login\", {email: \"example@example.com\", username: \"example\", password: \"example\"}).subscribe((res: any) => { Where email , username and password are the JSON parameters. As a result our backend model would look like: from pydantic import BaseModel # Module to create the models class PostLoginCheckStudentModel(BaseModel): email: str username: str password: str And the API would receive the call like so: @app.post(\"/api/check_student_login\") async def check_student_login_post(user: PostLoginCheckStudentModel): return check_student_login(user.email, user.password) # Calls a function on the backend These Data Structures are repeated throughout the API and are paramount to our data manipulation methods.","title":"Data Structures"},{"location":"Backend/#encryption","text":"Firstly, all passwords are encrypted before being stored in the backend. They are encrypted using Passlib's CryptContext module with 'bcrypt' as the schema. The password is encrypted with the following code: from pydantic import BaseModel # Import module pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\") # Identify the schema used def hash_password(password): # Take a plaintext password & convert it to ciphertext return pwd_context.hash(password) This will encrypt our password. It is extremely secure as each password is non-reversible. This results in the same input string having a variable output hash as the starting 'salt' used by the algorithm will be different. For example, an input password of 1234 could result in: - $2b$12$zProG7RawgHpdXZ9RfxYZ.pcwZy4N29C6mRzBb8yAFvoHc5TSSyZC - $2b$12$0DPNbWZDAX5fJl4pyBHnIuWiLk.2w/rxU/MnuKFznmjouUMjFxW5. - $2b$12$U6PDFiGrqooLxsnHJ7X9gehpzH3tLiI./BH8oj3HejMSyZvGHPneC - $2b$12$YJK4L0S8pcFKokWUYqf1VuDtjxy.KptvvBN9VTJIvTPTuwc36KwAe - $2b$12$MWwHq8PHskJqF2EoGOI60..J92SVyjD5FHVc4Ugbv7ZnD10Wso6yO - $2b$12$r5qvt.4ik//TSFaVWxWZ3uFGdmUXJL35.FXeeb2uDiWSQSZYQWv0i With there being a large number of potential passwords based on the starting 'salt'. To verify the value of our password, we do not reverse the hash. This is because reversing the hash is impossible. Instead, we use an inbuilt function that compares the plain-text to the hashed cipher-text. This functionality is used when authenticating a user during login and is done as such: from pydantic import BaseModel # Import module pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\") # Identify the schema used def verify_password(unhashed, hashed): return pwd_context.verify(unhashed, hashed) # Returns a boolean This function compares the original 'salt' and 'work factor' (Number of encryption iterations) and calculates whether the hash could have been derived from this input. If the algorithm deems it possible, then a boolean value of True is returned, otherwise the function returns False .","title":"Encryption"},{"location":"Backend/#tokens","text":"When the frontend needs to make any request to the backend, it needs to provide a token. This token is valid for 7 days and stores the name , email and id of the user (student) that is currently logged in. When a user attempts to login, the details they input are checked against the database. If the email and password inputted align with an email and password from the database, a token is created and sent to the frontend. The token is created using the code: def get_user_token(student: Student): to_encode = { 'details' : {'name': student.name, 'email': student.email, 'id': student.id}, 'expiry' : str(datetime.utcnow() + timedelta(minutes = ACCESS_TOKEN_EXPIRE_MINUTES)) } return jwt.encode(to_encode, SECRET_KEY, algorithm = ALGORITHM) Where SECRET_KEY is a 256-bit custom code that is used for encryption and the algorithm is HS256. This token is then stored in the user's browser data. As a result of this, the user will not have to log in to the website on every occurrence of accessing the website. The frontend injects this token into every request as shown by the code: @Injectable() export class CookieInterceptor implements HttpInterceptor { private platformId = inject(PLATFORM_ID); intercept(request: HttpRequest<unknown>, next: HttpHandler): Observable<HttpEvent<unknown>> { // Intercepts an incoming request let token: string | undefined; if (isPlatformBrowser(this.platformId)) { token = document.cookie.split(\"; \").find((row) => row.startsWith(\"token=\"))?.split(\"=\")[1]; } // Extracts the token from the web-browser const modifiedRequest = request.clone({ withCredentials: true, setHeaders: token ? { 'token': token } : {} // Adds the token to the request }); return next.handle(modifiedRequest); // Sends the request to the API } } Once the backend receives this token, it then verifies the token in every single function before even executing the intended request of the method call. This is done through the code: @app.post(\"/api/function_name\") async def function_name(request: Request): token_res = validate_student(request.headers.get('token')) # Runs a backend function to validate the token by extracting the user details and checking the expiry of the token if token_res == False: return JSONResponse(status_code=401, content={\"message\": \"Invalid token\"}) # Prevents any functions if the token is invalid else: # Execute the intended code here To validate the token, the code firsts calls the function validate_student() : def validate_student(token): try: res = get_student_from_token(token) if res == \"Token Expired\": # Checks if the token is past its expiry date return False else: # Returns details in the form of a list return [res['name'], res['email'], res['id']] # If the token is invalid, return False except InvalidTokenError: return False # If the token cannot be decoded, return False except InvalidSignatureError: # Checks if the user has tried to use token injection, resulting in an invalid token return False To get the res variable, our code initially decodes the token using the get_student_from_token(token: str) function: def get_student_from_token(token): payload = jwt.decode(token, SECRET_KEY, algorithms = [ALGORITHM]) expiry = payload.get('expiry') if datetime.utcnow() >= datetime.strptime(expiry, '%Y-%m-%d %H:%M:%S.%f'): # Compares the expiry date to the current date based on UCT return \"Token Expired\" else: return payload.get('details') # Returns the details as a dictionary of the name, email and UID This means that an expired or invalid token will immediately be rejected but a valid and correct token will be decoded. The app then performs all of its functions based on this data, allowing the app to extract the user's notes based on the OWNER_EMAIL property of each file, ensuring the privacy of user data and maintains the user experience. If the app returns a 401 error due to a bad token, the frontend intercepts this error and redirects the user to a login/sign-up page, as shown in the code: @Injectable() export class ErrorInterceptor implements HttpInterceptor { constructor(private router: Router, private route: ActivatedRoute) {} getChildRoute(route: ActivatedRoute): ActivatedRoute { while (route.firstChild) { route = route.firstChild; } return route; } intercept(request: HttpRequest<any>, next: HttpHandler): Observable<HttpEvent<any>> { const modifiedRequest = request.clone({ // Clones any incoming requests headers: request.headers.set('X-Requested-With', 'XMLHttpRequest'), withCredentials: true }); return next.handle(modifiedRequest).pipe( tap(() => {}, (err: any) => { if (err instanceof HttpErrorResponse) { // Checks if we have received an error if (err.status != 401 ) { return; } this.router.navigate(['/login']); // Prevents the request from going through and redirects to login page instead } })); } } This all ensures that the user can use the app easily, as they do not have to specify their ID when trying to use the app's functions whilst also preventing bad actors from accessing user data. There is one exception to each API call having a token requirements. This is the cloud_check() function and is used by me to check if the API is responding to API calls. It is a simple get API call: @app.get(\"/api/cloud_check\") async def cloud_check(): return True And was initially used by my service provider to notify me if my API goes down. This is the only potential vulnerability evident to me, and is more dependent on my provider's (Linode) protection to unauthorised IPv6 & IPv4 calls to the server. When calling the method, it should return the following page:","title":"Tokens"},{"location":"Backend/#storing-user-files","text":"When a user uploads a file, it is stored in our backend as a raw .PDF file. These files are not encrypted and are stored as their raw content. Their security is dependent upon the security of our service provider, Linode. The only feasible point of interception is when the file is being transmitted to the Backend from the Frontend. Before even allowing the data to be uploaded, we first have to verify its size. Gemini AI, like other commerical AIs converts input data and prompts to tokens that it can decode and understand. Similarly, input files are converted to tokens. There is a limit to the number of tokens that the AI can handle. To ensure that the files aren't too large (i.e. too many tokens), we use the count_tokens function of the API. This counts the tokens with the code: token_no = client.models.count_tokens(model=model_name,contents=client.files.upload(file=file_path, config={'display_name': 'test_data'})).total_tokens We then compare it to the limit, returning a boolean value depending on the result. However, we also have this statement encapsulated in a try...except... loop as if this request fails, then we know that the file is too large so we automatically reject it. NOTE: Files such as handwritten files have a lower capacity as they require more tokens and often cannot be decoded by the AI. To circumvent this, I am working on implementing a form of Vision AI to convert handwritten text to PDF Format. However, this also has its limitations.","title":"Storing user files"},{"location":"Backend/#volatile-data","text":"","title":"Volatile Data"},{"location":"Backend/#current-notes","text":"The note that the user currently has selected is stored as a python array, as this allows for quick read/write times and this data does not need to be permanent as the user can simply reselect the notes they are using.","title":"Current Notes"},{"location":"Backend/#caching","text":"We also have caching in place. Previously, it would take anywhere from 30s - 2min for the flashcard & question-answer functionality to respond. To avoid this, any generated flashcards are stored in an array. Before generating them, the code checks if flashcards for the given notes already exist. If they do, then those flashcards are returned. If not, flashcards are generated and stored. Similarly, the code generates 10 questions at a time and stores them in an array relative to the file. When a question is requested, a question is removed from this list and sent. Once the number of cached questions drops below 3, a new set of questions are requested from the AI. This reduces the wait-time for the user and also makes it more cost-effective on my part as I have to pay for fewer requests, albeit there is a larger size per request.","title":"Caching"},{"location":"Backend/#non-volatile-data","text":"","title":"Non-volatile data"},{"location":"Backend/#notes","text":"The notes stored are non-volatile as they are stored as PDF data.","title":"Notes"},{"location":"Backend/#login-data","text":"User information such as their emails, password and UID's are stored in a sqlite3 database on the SSD of our server","title":"Login Data"},{"location":"Backend/#tokens_1","text":"Tokens are actually stored on the browser, and sent to the backend on a per-request basis. The Backend simply verifies their validity therefore they are considered non-volatile.","title":"Tokens"},{"location":"Core%20Functions/","text":"Summarisations Firstly, we created the ability for the user to summarise their notes with the click of a button. When the notes are uploaded, the user should simply navigate to the 'Summarise' tab on the NavBar and click summarise (with their notes selected of course) and wait before seeing their notes condensed into a much more digestible format. For example, the user would see the following: As you can see, there is also support for Rich Text, which is commonly returned by the AI's API. This allows for easier reading and was implemented later. For more information, view the improvements section To get the AI to summarise, the code was as follows: def summariser(noteID): notes = upload_notes(noteID) # Uploads notes to AI as context return (run_prompt(notes, \"Summarise the notes\")) Flashcards For flashcards, we added the data as context and simply asked the AI to return the data as a json object and gave an example of the intended format of the return data. Additionally, we used a data cleaner to remove any additional rich text characteristics as otherwise, our code would not have been able to parse the data. This was done using the following prompt: def flashcards(noteID): for i in range(len(CACHED_FLASHCARDS)): # Initially Checks to see if the flashcards are already present in the Cache if CACHED_FLASHCARDS[i][0] == noteID: return CACHED_FLASHCARDS[i][1] notes = upload_notes(noteID) cards = str((model.generate_content( [notes, \"Make flashcards for the notes given. Make these short flashcards witha back of no more than 20 words. Return the data as a json object without any additional formatting or rich text backticks/identifiers LISTEN TO ME NO BACKTICS OR IDENTIFIERS do not put the json identifier. A good example of how you should do it is this: [{'Front': 'I am the front of Card 1', 'Back': 'I am the back of Card 1'}, {'Front': 'I am the front of Card 2', 'Back': 'I am the back of Card 2'}d]\"])).text) # This is the prompt flashcards = data_cleaner(cards, True, True) # Cleans data CACHED_FLASHCARDS.append([noteID, flashcards]) return flashcards The data cleaner's code: def data_cleaner(value, remove_new_line: bool, isJson: bool): # Just cleans the data value = value.strip() value = re.sub('[`]', '', value) if (remove_new_line): value = value.replace(\"\\n\", \"\") value = value.title() if (isJson): value = json.loads(value[value.index(\"[\"):]) return value This is the advantage of AI, as a majority of the data parsing can simply be instructed to the AI as its task, and the AI does it. Question & Answers When the user requests a question to answer, the backend first checks the cache if there is an existing question deck. If there is, the code pulls a question out and removes it from the deck. If there is no existing deck, the code generates a deck of questions, pulls a question, removes it from the deck and adds it to the cache. If the number of questions in the deck dips below 3, the deck is regenerated. This can be seen by the code below: def make_questions(noteID): curr_questions = [] iter = -1 for i in range(len(CACHED_QUESTIONS)): if CACHED_QUESTIONS[i][0] == noteID: curr_questions = CACHED_QUESTIONS[i][1] iter = i break if iter == -1: CACHED_QUESTIONS.append([noteID, []]) iter = len(CACHED_QUESTIONS) - 1 if curr_questions == [] or len(curr_questions) < 3: notes = upload_notes(noteID) try: res = str((model.generate_content( [notes, f\"Generate 10 questions on these notes. Return the data as a python array without any additional formatting or rich text backticks/identifiers. ONLY GIVE THE QUESTIONS AND NO ANSWERS. DONT REPEAT QUESTIONS YOU HVAE ASKED IN THE CURRENT SESSION\"])).text) res = ast.literal_eval(data_cleaner(res, True, False)) CACHED_QUESTIONS[iter][1] = res CACHED_QUESTIONS[iter][1].pop(0) curr_questions = CACHED_QUESTIONS[iter][1] return curr_questions[0] except: return \"Error generating questions, please try again in a few minutes\" else: CACHED_QUESTIONS[iter][1].pop(0) return curr_questions[0] When the user wants to check the answer to their question, the backend receives the question, the user's answer and the ID of the file that the question is from. The backend then sends all of this data as context to the AI and asks it to return whether the given answer is valid for the question depending on the context - i.e. the file. This can be seen by the code below: def check_question(question, answer, noteID): notes = upload_notes(noteID) res = (model.generate_content( [notes, f\"is the answer {answer} correct for the question {question}\"])).text return res The UI looks as follows: Custom Prompt Here, the user can communicate with the AI as they please using their notes as context. This creates a user-friendly, attractive environment that allows students to expand on the knowledge of their notes. For example, below is an example of the AI creating a Haiku based on their notes, as per the user's request. Additionally, you can stack these responses. Asking a new question will not delete the previous response, unless you reload the page. There is simply a divider that will be placed between the previous response and the current response","title":"Core Functions"},{"location":"Core%20Functions/#summarisations","text":"Firstly, we created the ability for the user to summarise their notes with the click of a button. When the notes are uploaded, the user should simply navigate to the 'Summarise' tab on the NavBar and click summarise (with their notes selected of course) and wait before seeing their notes condensed into a much more digestible format. For example, the user would see the following: As you can see, there is also support for Rich Text, which is commonly returned by the AI's API. This allows for easier reading and was implemented later. For more information, view the improvements section To get the AI to summarise, the code was as follows: def summariser(noteID): notes = upload_notes(noteID) # Uploads notes to AI as context return (run_prompt(notes, \"Summarise the notes\"))","title":"Summarisations"},{"location":"Core%20Functions/#flashcards","text":"For flashcards, we added the data as context and simply asked the AI to return the data as a json object and gave an example of the intended format of the return data. Additionally, we used a data cleaner to remove any additional rich text characteristics as otherwise, our code would not have been able to parse the data. This was done using the following prompt: def flashcards(noteID): for i in range(len(CACHED_FLASHCARDS)): # Initially Checks to see if the flashcards are already present in the Cache if CACHED_FLASHCARDS[i][0] == noteID: return CACHED_FLASHCARDS[i][1] notes = upload_notes(noteID) cards = str((model.generate_content( [notes, \"Make flashcards for the notes given. Make these short flashcards witha back of no more than 20 words. Return the data as a json object without any additional formatting or rich text backticks/identifiers LISTEN TO ME NO BACKTICS OR IDENTIFIERS do not put the json identifier. A good example of how you should do it is this: [{'Front': 'I am the front of Card 1', 'Back': 'I am the back of Card 1'}, {'Front': 'I am the front of Card 2', 'Back': 'I am the back of Card 2'}d]\"])).text) # This is the prompt flashcards = data_cleaner(cards, True, True) # Cleans data CACHED_FLASHCARDS.append([noteID, flashcards]) return flashcards The data cleaner's code: def data_cleaner(value, remove_new_line: bool, isJson: bool): # Just cleans the data value = value.strip() value = re.sub('[`]', '', value) if (remove_new_line): value = value.replace(\"\\n\", \"\") value = value.title() if (isJson): value = json.loads(value[value.index(\"[\"):]) return value This is the advantage of AI, as a majority of the data parsing can simply be instructed to the AI as its task, and the AI does it.","title":"Flashcards"},{"location":"Core%20Functions/#question-answers","text":"When the user requests a question to answer, the backend first checks the cache if there is an existing question deck. If there is, the code pulls a question out and removes it from the deck. If there is no existing deck, the code generates a deck of questions, pulls a question, removes it from the deck and adds it to the cache. If the number of questions in the deck dips below 3, the deck is regenerated. This can be seen by the code below: def make_questions(noteID): curr_questions = [] iter = -1 for i in range(len(CACHED_QUESTIONS)): if CACHED_QUESTIONS[i][0] == noteID: curr_questions = CACHED_QUESTIONS[i][1] iter = i break if iter == -1: CACHED_QUESTIONS.append([noteID, []]) iter = len(CACHED_QUESTIONS) - 1 if curr_questions == [] or len(curr_questions) < 3: notes = upload_notes(noteID) try: res = str((model.generate_content( [notes, f\"Generate 10 questions on these notes. Return the data as a python array without any additional formatting or rich text backticks/identifiers. ONLY GIVE THE QUESTIONS AND NO ANSWERS. DONT REPEAT QUESTIONS YOU HVAE ASKED IN THE CURRENT SESSION\"])).text) res = ast.literal_eval(data_cleaner(res, True, False)) CACHED_QUESTIONS[iter][1] = res CACHED_QUESTIONS[iter][1].pop(0) curr_questions = CACHED_QUESTIONS[iter][1] return curr_questions[0] except: return \"Error generating questions, please try again in a few minutes\" else: CACHED_QUESTIONS[iter][1].pop(0) return curr_questions[0] When the user wants to check the answer to their question, the backend receives the question, the user's answer and the ID of the file that the question is from. The backend then sends all of this data as context to the AI and asks it to return whether the given answer is valid for the question depending on the context - i.e. the file. This can be seen by the code below: def check_question(question, answer, noteID): notes = upload_notes(noteID) res = (model.generate_content( [notes, f\"is the answer {answer} correct for the question {question}\"])).text return res The UI looks as follows:","title":"Question &amp; Answers"},{"location":"Core%20Functions/#custom-prompt","text":"Here, the user can communicate with the AI as they please using their notes as context. This creates a user-friendly, attractive environment that allows students to expand on the knowledge of their notes. For example, below is an example of the AI creating a Haiku based on their notes, as per the user's request. Additionally, you can stack these responses. Asking a new question will not delete the previous response, unless you reload the page. There is simply a divider that will be placed between the previous response and the current response","title":"Custom Prompt"},{"location":"Frontend/","text":"A well designed API needs a well-designed frontend to allow the user to use the API well. To do this, I had to utilise functions that had the user in mind. This included things such as Angular, Angular Material, and the Google Icon Library. Router Firstly, we needed to allow users to navigate through the pages. This was done through the use of angular's routers. Angular is a component-based framework. This means that each page is its own component. To allow for navigation and appropriate displaying of the correct component, we have to code the correct paths in. This is done like so: export const routes: Routes = [ { path: '', component: DashboardComponent // DASHBOARD COMPONENT }, { path: 'custom-prompt', component: CustomPromptComponent }, { path: 'flashcards', component: FlashcardsComponent }, { path: 'question-answer', component: QuestionAnswerComponent }, { path: 'summariser', component: SummariserComponent }, { path: 'login', component: LoginComponent }, { path: 'sign-up', component: SignUpComponent }, { path: 'student-profile', component: ViewStudentProfileComponent }, { path: 'add-section', component: AddSectionComponent } ]; Where each path is the URL path. So the FlashcardComponent could be found at the URL https://studdybuddy.app/flashcards This also allows for navigation within the code. For example, if a user is not logged in, the code automatically navigates them to the login page with the code: this.router.navigate(['/login']); Interceptors When something is not correct, for example if a user is not logged in or there is an error returned by the backend, the code has to intercept it to ensure that the frontend does not display these errors and allow them to correct the mistake without confusing them. Cookie Firstly, we have the cookie interceptor component. The code is: import { Injectable, inject } from '@angular/core'; import { HttpRequest, HttpHandler, HttpEvent, HttpInterceptor } from '@angular/common/http'; import { Observable } from 'rxjs'; import { PLATFORM_ID } from '@angular/core'; import { isPlatformBrowser } from '@angular/common'; @Injectable() export class CookieInterceptor implements HttpInterceptor { private platformId = inject(PLATFORM_ID); intercept(request: HttpRequest<unknown>, next: HttpHandler): Observable<HttpEvent<unknown>> { let token: string | undefined; if (isPlatformBrowser(this.platformId)) { token = document.cookie.split(\"; \") .find((row) => row.startsWith(\"token=\")) ?.split(\"=\")[1]; } const modifiedRequest = request.clone({ withCredentials: true, setHeaders: token ? { 'token': token } : {} }); return next.handle(modifiedRequest); } } This code extracts a token from the user's browser storage and automatically adds it to every request that is sent. This ensure that the user is authenticated to prevent injection to the Gemini API. Error If the backend returns an error, particularly a 401 error indicating that a user is not logged in (from an invalid cookie), the frontend intercepts it to prevent the app from stopping or halting. The code is: import { Injectable } from '@angular/core'; import { HttpRequest, HttpHandler, HttpEvent, HttpInterceptor, HttpErrorResponse } from '@angular/common/http'; import { Observable } from 'rxjs'; import { Router , ActivatedRoute, NavigationEnd} from '@angular/router'; import {tap, filter} from 'rxjs/operators'; @Injectable() export class ErrorInterceptor implements HttpInterceptor { constructor(private router: Router, private route: ActivatedRoute) {} getChildRoute(route: ActivatedRoute): ActivatedRoute { while (route.firstChild) { route = route.firstChild; } return route; } intercept(request: HttpRequest<any>, next: HttpHandler): Observable<HttpEvent<any>> { const modifiedRequest = request.clone({ headers: request.headers.set('X-Requested-With', 'XMLHttpRequest'), withCredentials: true }); return next.handle(modifiedRequest).pipe( tap(() => {}, (err: any) => { if (err instanceof HttpErrorResponse) { if (err.status != 401 ) { return; } this.router.navigate(['/login']); } })); } } Here, the code intercepts all incoming requests. If the response has a code of 401, it automatically redirects to the login page and discards the contents of the request. This prevents an error from reaching the user and causing the app to halt. Snackbars Some of these requests take time before the AI can respond. To let the user know, I used Angular-Material's snackbars to prevent the user from leaving the page prematurely due to a request taking time. For example, below is the snackbar that appears when a user requests to create flashcards. This is the snackbar that appears when the user tries to create flashcards, ensuring that the user is not confused by wait times. Additionally, the snackbar can also be used to display errors. For example, if the user does not have an existing account and tries to login, the app returns a separate snackbar, as shown below: This indicates to the user that they need to sign in. Flashcards When the flashcards are requested, we use a custom-built component that was taken from a StackBlitz repository to display them. This can be seen below: This creates a friendly environment for the user to interact with their flashcards. There is a display of the flashcard they are currently looking at and there is buttons to flip between the various flashcards. Additionally, the user can just click the flashcard to view its behind side. Animations When flipping between the sides of the flashcards, there is an animations which can be seen below: This brings a better user experience as it adds fluidity to the app. The code to do this is the following: animations: [ trigger('flipState', [ // Triggered when the user clicks the flashcards state('active', style({ transform: 'rotateY(179deg)' })), state('inactive', style({ transform: 'rotateY(0)' })), transition('active => inactive', animate('500ms ease-out')), transition('inactive => active', animate('500ms ease-in')) ]) ] HTTP Requests Every single component makes an HTTP request. We do this with the general format of the GET/POST Request as shown in the code below: // For a POST Request this.http.post(this.URL + \"API_REQUEST\", DATA).subscribe((res: any) => { }) // For a GET Request this.http.get(this.URL + \"/API_REQUEST\").subscribe((res: any) => { }) Angular Material I wanted the app to look good. To do this, I used premade components from a proprietary npm module called Angular Material . From here, I have taken various components such as: The NavBar The Side Tree The aforementioned snack bar And many more This creates fluidity and cleanliness in the app and also adds a dynamic layer as these components are scaleable to the size of their display, creating a better user experience Icons I used the google Icon library to simplify the purpose of some buttons into images rather than words to reduce the page's clutter. They have been used in various places such as: - The menu Row - Each node on the side bar","title":"Frontend"},{"location":"Frontend/#router","text":"Firstly, we needed to allow users to navigate through the pages. This was done through the use of angular's routers. Angular is a component-based framework. This means that each page is its own component. To allow for navigation and appropriate displaying of the correct component, we have to code the correct paths in. This is done like so: export const routes: Routes = [ { path: '', component: DashboardComponent // DASHBOARD COMPONENT }, { path: 'custom-prompt', component: CustomPromptComponent }, { path: 'flashcards', component: FlashcardsComponent }, { path: 'question-answer', component: QuestionAnswerComponent }, { path: 'summariser', component: SummariserComponent }, { path: 'login', component: LoginComponent }, { path: 'sign-up', component: SignUpComponent }, { path: 'student-profile', component: ViewStudentProfileComponent }, { path: 'add-section', component: AddSectionComponent } ]; Where each path is the URL path. So the FlashcardComponent could be found at the URL https://studdybuddy.app/flashcards This also allows for navigation within the code. For example, if a user is not logged in, the code automatically navigates them to the login page with the code: this.router.navigate(['/login']);","title":"Router"},{"location":"Frontend/#interceptors","text":"When something is not correct, for example if a user is not logged in or there is an error returned by the backend, the code has to intercept it to ensure that the frontend does not display these errors and allow them to correct the mistake without confusing them.","title":"Interceptors"},{"location":"Frontend/#cookie","text":"Firstly, we have the cookie interceptor component. The code is: import { Injectable, inject } from '@angular/core'; import { HttpRequest, HttpHandler, HttpEvent, HttpInterceptor } from '@angular/common/http'; import { Observable } from 'rxjs'; import { PLATFORM_ID } from '@angular/core'; import { isPlatformBrowser } from '@angular/common'; @Injectable() export class CookieInterceptor implements HttpInterceptor { private platformId = inject(PLATFORM_ID); intercept(request: HttpRequest<unknown>, next: HttpHandler): Observable<HttpEvent<unknown>> { let token: string | undefined; if (isPlatformBrowser(this.platformId)) { token = document.cookie.split(\"; \") .find((row) => row.startsWith(\"token=\")) ?.split(\"=\")[1]; } const modifiedRequest = request.clone({ withCredentials: true, setHeaders: token ? { 'token': token } : {} }); return next.handle(modifiedRequest); } } This code extracts a token from the user's browser storage and automatically adds it to every request that is sent. This ensure that the user is authenticated to prevent injection to the Gemini API.","title":"Cookie"},{"location":"Frontend/#error","text":"If the backend returns an error, particularly a 401 error indicating that a user is not logged in (from an invalid cookie), the frontend intercepts it to prevent the app from stopping or halting. The code is: import { Injectable } from '@angular/core'; import { HttpRequest, HttpHandler, HttpEvent, HttpInterceptor, HttpErrorResponse } from '@angular/common/http'; import { Observable } from 'rxjs'; import { Router , ActivatedRoute, NavigationEnd} from '@angular/router'; import {tap, filter} from 'rxjs/operators'; @Injectable() export class ErrorInterceptor implements HttpInterceptor { constructor(private router: Router, private route: ActivatedRoute) {} getChildRoute(route: ActivatedRoute): ActivatedRoute { while (route.firstChild) { route = route.firstChild; } return route; } intercept(request: HttpRequest<any>, next: HttpHandler): Observable<HttpEvent<any>> { const modifiedRequest = request.clone({ headers: request.headers.set('X-Requested-With', 'XMLHttpRequest'), withCredentials: true }); return next.handle(modifiedRequest).pipe( tap(() => {}, (err: any) => { if (err instanceof HttpErrorResponse) { if (err.status != 401 ) { return; } this.router.navigate(['/login']); } })); } } Here, the code intercepts all incoming requests. If the response has a code of 401, it automatically redirects to the login page and discards the contents of the request. This prevents an error from reaching the user and causing the app to halt.","title":"Error"},{"location":"Frontend/#snackbars","text":"Some of these requests take time before the AI can respond. To let the user know, I used Angular-Material's snackbars to prevent the user from leaving the page prematurely due to a request taking time. For example, below is the snackbar that appears when a user requests to create flashcards. This is the snackbar that appears when the user tries to create flashcards, ensuring that the user is not confused by wait times. Additionally, the snackbar can also be used to display errors. For example, if the user does not have an existing account and tries to login, the app returns a separate snackbar, as shown below: This indicates to the user that they need to sign in.","title":"Snackbars"},{"location":"Frontend/#flashcards","text":"When the flashcards are requested, we use a custom-built component that was taken from a StackBlitz repository to display them. This can be seen below: This creates a friendly environment for the user to interact with their flashcards. There is a display of the flashcard they are currently looking at and there is buttons to flip between the various flashcards. Additionally, the user can just click the flashcard to view its behind side.","title":"Flashcards"},{"location":"Frontend/#animations","text":"When flipping between the sides of the flashcards, there is an animations which can be seen below: This brings a better user experience as it adds fluidity to the app. The code to do this is the following: animations: [ trigger('flipState', [ // Triggered when the user clicks the flashcards state('active', style({ transform: 'rotateY(179deg)' })), state('inactive', style({ transform: 'rotateY(0)' })), transition('active => inactive', animate('500ms ease-out')), transition('inactive => active', animate('500ms ease-in')) ]) ]","title":"Animations"},{"location":"Frontend/#http-requests","text":"Every single component makes an HTTP request. We do this with the general format of the GET/POST Request as shown in the code below: // For a POST Request this.http.post(this.URL + \"API_REQUEST\", DATA).subscribe((res: any) => { }) // For a GET Request this.http.get(this.URL + \"/API_REQUEST\").subscribe((res: any) => { })","title":"HTTP Requests"},{"location":"Frontend/#angular-material","text":"I wanted the app to look good. To do this, I used premade components from a proprietary npm module called Angular Material . From here, I have taken various components such as: The NavBar The Side Tree The aforementioned snack bar And many more This creates fluidity and cleanliness in the app and also adds a dynamic layer as these components are scaleable to the size of their display, creating a better user experience","title":"Angular Material"},{"location":"Frontend/#icons","text":"I used the google Icon library to simplify the purpose of some buttons into images rather than words to reduce the page's clutter. They have been used in various places such as: - The menu Row - Each node on the side bar","title":"Icons"}]}